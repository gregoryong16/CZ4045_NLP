{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce GTX 1650\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it really is not but good to know you will bel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>indeed i will let us take a teensy fraction of...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>actually its not not only have child drag been...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>government considering repeal of sodomy law al...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on a clear day you can see forever opening nig...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  it really is not but good to know you will bel...      1\n",
       "1  indeed i will let us take a teensy fraction of...      2\n",
       "2  actually its not not only have child drag been...      1\n",
       "3  government considering repeal of sodomy law al...      2\n",
       "4  on a clear day you can see forever opening nig...      2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/dataset.csv\", usecols=['text','label'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19835, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    8846\n",
       "1    7308\n",
       "0    3681\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "seed_val = 17 \n",
    "random.seed(seed_val) \n",
    "np.random.seed(seed_val) \n",
    "torch.manual_seed(seed_val) \n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'], \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    stratify=df['label'])\n",
    "\n",
    "# we will use temp_text and temp_labels to create validation and test set\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "                                                                test_size=0.5, \n",
    "                                                                stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "\n",
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased', return_dict=False)\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['â„¢', 'ğŸ™„', 'âœ…', 'ğŸ’—', 'ğŸ˜¢', 'ğŸ³ï¸\\u200dğŸŒˆ', 'ğŸ˜Œ', 'ğŸ³', 'ğŸ’€', 'ğŸŒˆ', 'ğŸ‘ğŸ»', 'âœ¨', 'ğŸŒŸ', 'ğŸŒ¹', 'ğŸ˜•', 'â­', 'ğŸ˜…', 'ğŸ™', 'ğŸ’', 'ğŸ§', 'ğŸ˜­', 'ğŸ–¤', 'ğŸ¤§', 'ğŸ¤£', 'ğŸ—ƒï¸', 'ğŸ—“ï¸', 'â¡ï¸', 'ğŸ”»', 'ğŸ¤¤', 'ğŸŒ', 'ğŸ˜', 'â¤ï¸', 'â¤', 'ğŸ‘', 'ğŸ˜', 'ğŸ‘½', 'ğŸš€', 'ğŸ“š', 'ğŸ±', 'ğŸŒŒ', 'ğŸ˜©', 'ğŸ¤·\\u200dâ™€ï¸', 'ğŸ˜¬', 'ğŸ¦„', 'ğŸ¤¸\\u200dâ™€ï¸', 'â˜€ï¸', 'ğŸ‘ğŸ¼', 'ğŸ”†', 'ğŸ—£', 'ğŸ‘€', 'ğŸ‘ğŸ»', 'ğŸ§‘\\u200dğŸ¤\\u200dğŸ§‘', 'ğŸŠ', 'â˜¹ï¸', 'ğŸ¥°', 'ğŸ’–', 'ğŸ¤­', 'ğŸ‘', 'ğŸµ', 'ğŸ¶', 'ğŸ˜Š', 'ğŸ‘ŒğŸ¼', 'ğŸ¤ŸğŸ¼', 'ğŸ’ªğŸ¼', 'ğŸ”¥', 'ğŸ»', 'ğŸº', 'ğŸ˜‚', 'â™¥ï¸', 'ğŸ¤¡', 'ğŸ’š', 'ğŸ’™', 'ğŸ’œ', 'ğŸ¤”', 'ğŸ¹', 'ğŸ¸', 'ğŸ‘Œ', 'ğŸ ', 'ğŸ™ƒ', 'ğŸš«', 'ğŸ‘‡', 'ğŸ˜†', 'ğŸ˜€', 'ğŸ¤ª', 'ğŸ¤·ğŸ¼\\u200dâ™‚ï¸', 'ğŸ¥º', 'ğŸ“¦', 'ğŸƒ', 'ğŸ’¨', 'ğŸŒ…', 'ğŸ', 'ğŸ‘¬ğŸ»', 'ğŸ¥µ', 'ğŸ§µ', 'ğŸ˜°', 'ğŸ’…', 'ğŸ‘¨\\u200dâ¤ï¸\\u200dğŸ‘¨', 'ğŸ‘¨\\u200dâ¤ï¸\\u200dğŸ’‹\\u200dğŸ‘¨', 'ğŸ˜”', 'ğŸ˜‡', 'ğŸ¤«', 'ğŸ™ğŸ»', 'ğŸ¤·\\u200dâ™‚ï¸', 'ğŸ‡§ğŸ‡¿', 'ğŸ˜', 'ğŸ“£', 'ğŸ¤¢', 'ğŸ˜ƒ', 'ğŸ˜¡', 'ğŸ’«', 'ğŸ’', 'ğŸ§›\\u200dâ™€ï¸', 'ğŸ¥€', 'ğŸ¹', 'â„¢ï¸', 'ğŸ˜º', 'ğŸ¤', 'ğŸ’›', 'ğŸ§¡', 'ğŸ’•', 'âœ‹', 'ğŸ—½', 'ğŸƒ', 'ğŸ‡·ğŸ‡º', 'ğŸ¤ ', 'ğŸ’‹', 'ğŸ¤¯', 'ğŸ©', 'ğŸ§', 'ğŸ°', 'âœŒï¸', 'ğŸ‘¨', 'ğŸ‘¨ğŸ¼', 'ğŸ¥´', 'ğŸ’”', 'ğŸ‘', 'Â®', 'ğŸ˜', 'ğŸ•', 'ğŸ’©', 'ğŸ¨', 'ğŸ˜‰', 'ğŸ§', 'ğŸ‘ğŸ¾', 'ğŸ˜³', 'ğŸ¥³', 'ğŸ¤¦\\u200dâ™€ï¸', 'ğŸ‘‡ğŸ½', 'ğŸ”º', 'ğŸ™Œ', 'âŒ', 'â­•', 'ğŸ˜™', 'ğŸ¤¦\\u200dâ™‚ï¸', 'ğŸ¤¦\\u200dâ™‚', 'ğŸ˜‘', 'ğŸ’¥', 'â¡', 'ğŸ”´', 'ğŸ®', 'ğŸš‘', 'â›‘ï¸', 'ğŸ˜', 'ğŸ—£ï¸', 'ğŸ’¬', 'ğŸ˜¿', 'ğŸ˜ˆ', 'ğŸ˜', 'ğŸ’Ÿ', 'â–¶ï¸', 'ğŸŒ', 'ğŸŒ', 'ğŸ¤®', 'ğŸ’ªğŸ»', 'ğŸ˜’', 'âœŠğŸ¾', 'â˜', 'ğŸ¦‰', 'ğŸ™‚', 'ğŸ“–', 'ğŸ‰', 'ğŸ¤·ğŸ»\\u200dâ™‚ï¸', 'ğŸ…°ï¸', 'ğŸ“Œ', 'ğŸ“·', 'ğŸ‘ğŸ¼', 'â”', 'ğŸ‘¶ğŸ»', 'ğŸ‘§ğŸ»', 'ğŸ™ˆ', 'ğŸ˜˜', 'ğŸ‡', 'ğŸ¿', 'âš«', 'ğŸ‘‹', 'ğŸ˜ª', 'ğŸ’‰', 'â˜ ï¸', 'ğŸ‡ºğŸ‡²', 'ğŸ¤¦', 'ğŸ˜¶', 'ğŸ’“', 'â˜º', 'ğŸ³\\u200dğŸŒˆ', 'âš“', 'ğŸ¥‚', 'Â©ï¸', 'âœŠ', '1ï¸âƒ£', '5ï¸âƒ£', 'ğŸ˜', 'ğŸ¤¦ğŸ»\\u200dâ™‚ï¸', 'ğŸ‡¨ğŸ‡¦', 'ğŸ˜£', 'ğŸš’', 'âœŠğŸ½', 'ğŸ¤¬', 'ğŸ‡ºğŸ‡¦', 'ğŸ¥', 'ğŸ¾', 'ğŸš¨', 'â˜ï¸', 'ğŸ¤·ğŸ½\\u200dâ™€ï¸', 'ğŸ¤¨', 'âœï¸', 'ğŸ’…ğŸ»', 'â¬‡', 'ğŸŒ»', 'ğŸ˜·', 'ğŸ¦‹', 'ğŸŒ³', 'ğŸ¦¥', 'ğŸ¤', 'ğŸ“', 'ğŸ˜„', 'ğŸ˜“', 'ğŸ’ğŸ»\\u200dâ™‚ï¸', 'ğŸš©', 'ğŸ¤¦ğŸ¼\\u200dâ™‚ï¸', 'ğŸ’', 'ğŸ‘‘', 'âœŒ', 'ğŸ§', 'ğŸ¤¦ğŸ¾\\u200dâ™‚ï¸', 'ğŸŒ¸', 'ğŸ–‹', 'ğŸ“¨', 'ğŸ“', 'ğŸ•', 'ğŸ‘®\\u200dâ™‚ï¸', 'ğŸš”', 'ğŸ‘®\\u200dâ™€ï¸', 'ğŸ¤·ğŸ¼\\u200dâ™€ï¸', 'ğŸ–•', 'ğŸ¤¦ğŸ½\\u200dâ™€ï¸', 'ğŸ•“', 'ğŸ‘¹', 'ğŸ¤©', 'ğŸ‘‰', 'ğŸ‘ˆ', 'ğŸ“¼', 'ğŸ›‘', 'â˜', 'âœğŸ»', 'ğŸ˜ ', 'ğŸ€', 'ğŸ¤œğŸ½', 'ğŸ¤›ğŸ½', 'ğŸ”—', 'ğŸ¥', 'ğŸ™‹', 'ğŸ—‘', 'ğŸ‘®ğŸ»\\u200dâ™‚ï¸', 'ğŸ‘·ğŸ¼\\u200dâ™€ï¸', 'ğŸ¥±', 'ğŸ˜»', 'ğŸ‡µğŸ‡¸', 'ğŸ‘¾', 'ğŸš', 'â„ï¸', 'ğŸ‡¸ğŸ‡©', 'ğŸ‡¸ğŸ‡²', 'â˜ºï¸', 'ğŸ¦Š', 'ğŸ‘»', 'ğŸ¤', 'ğŸ˜š', 'â—', 'ğŸ˜¤', 'ğŸ˜œ', 'ğŸ§‘', 'ğŸ¼', 'ğŸ‡¦ğŸ‡«', 'ğŸ‘', 'ğŸ‘ï¸', 'ğŸ™…ğŸ»\\u200dâ™€ï¸', 'ğŸ•ºğŸ½', 'ğŸ˜¨', 'ğŸ˜¥', 'ğŸ“º', 'ğŸ¬', 'ğŸ“', 'ğŸŒï¸\\u200dâ™‚ï¸', 'â›³', 'ğŸ¨', 'ğŸ”', 'ğŸŸ', 'ğŸ’ª', 'ğŸ‘‡ğŸ»', 'ğŸ‡ºğŸ‡¸', 'âœŠğŸ¼', 'ğŸ–•ğŸ»', 'ğŸ˜±', 'ğŸ”«', 'â™£ï¸', 'ğŸ”–', 'â¬œ', 'ğŸ“•', 'ğŸ‘¿', 'ğŸ™ğŸ¼', 'ğŸ˜¦', 'ğŸ¯', 'ğŸ¦µğŸ¿', 'ğŸ’ƒ', 'ğŸ¦…', 'ğŸ‚', 'â¬‡ï¸', 'ğŸ’¸', 'ğŸ’¯', 'âœŠğŸ»', 'ğŸ¦ˆ', 'ğŸ€', 'ğŸ‘ğŸ½', 'â˜®ï¸', 'ğŸ˜«', 'ğŸ™‹ğŸ»\\u200dâ™€ï¸', 'ğŸ‘„', 'ğŸ‚', 'ğŸ§›\\u200dâ™€', 'âš”', 'ğŸ˜Ÿ', 'ğŸ‡·ğŸ‡¸', 'ğŸ‡¬ğŸ‡ª', 'â¤µï¸', 'ğŸ˜‹', 'ğŸ‡§ğŸ‡¬', 'ğŸ‡±ğŸ‡»', 'ğŸ‡·ğŸ‡´', 'ğŸ‡¸ğŸ‡°', 'ğŸ‡¨ğŸ‡¿', 'ğŸ‡µğŸ‡±', 'ğŸ‡±ğŸ‡¹', 'ğŸ‡ªğŸ‡ª', 'ğŸ‡­ğŸ‡º', 'ğŸ‡¸ğŸ‡®', 'ğŸ‡§ğŸ‡¦', 'ğŸ‡²ğŸ‡ª', 'ğŸ‡¦ğŸ‡±', 'ğŸ‡²ğŸ‡°', 'ğŸ‡½ğŸ‡°', 'ğŸ‡­ğŸ‡·', 'ğŸ‡¬ğŸ‡·', 'âœ”ï¸', 'âœŒğŸ»', 'ğŸ', 'ğŸ¯', 'ğŸ¤·\\u200dâ™‚', 'ğŸ“¸', 'ğŸ¥', 'âœ', 'ğŸ™ğŸ¼\\u200dâ™€ï¸', 'ğŸ™ğŸ¾\\u200dâ™€', 'ğŸ‘ŒğŸ¿', 'ğŸ™ŒğŸ¿', 'ğŸ‘†', 'ğŸ§\\u200dâ™€ï¸', 'ğŸ¤·ğŸ¼', 'ğŸ’ğŸ¾\\u200dâ™€ï¸', 'ğŸ–', 'â™€ï¸', 'âš°ï¸', 'ğŸ¦´', 'ğŸš¦', 'â›‘', 'ğŸ¤š', 'ğŸ·', 'ğŸšŒ', 'â€¼ï¸', 'â‰ï¸', 'ğŸ˜®', 'ğŸ‰', 'ğŸ¤¦ğŸ¼\\u200dâ™€ï¸', 'ğŸŒ–', 'ğŸ¦', 'ğŸ„', 'ğŸ§ ', 'â™¥', 'ğŸ˜¯', 'ğŸ‘Š', 'ğŸ“ˆ', 'âš•ï¸', 'ğŸ‡ºğŸ‡³', 'ğŸ¤·', 'ğŸ†“', 'ğŸ“±', 'ğŸ›Œ', 'ğŸŒŠ', 'ğŸˆ', 'ğŸ‘—', 'ğŸ™‰', 'ğŸ´\\u200dâ˜ ï¸', 'ğŸ¤¦ğŸ»', 'ğŸ¤·ğŸ»\\u200dâ™€ï¸', 'âš”ï¸', 'ğŸ‘ ', 'ğŸ˜–', 'ğŸ§»', 'ğŸ¶', 'ğŸ˜›', 'ğŸ¤™', 'ğŸ‘‡ğŸ¼', 'ğŸ¤“', 'âœ¡ï¸', 'ğŸ‘ŠğŸ½', 'ğŸ’ªğŸ½', 'ğŸ¿', 'ğŸ™ğŸ¾', 'ğŸ•´', 'ğŸ¤šğŸ»', 'ğŸ¡', 'ğŸ‘©\\u200dğŸ«', 'ğŸ“¢', 'ğŸ¤', 'ğŸ‘‰ğŸ¼', 'ğŸ‘ğŸ½', 'âš¡', 'ğŸ†', 'ğŸ‡·ğŸ‡¼', 'ğŸ‡¸ğŸ‡¿', 'ğŸ‡»ğŸ‡³', 'â˜¯ï¸', 'â˜•', 'ğŸ‘‹ğŸ»', 'ğŸ¤·ğŸ½\\u200dâ™‚ï¸', 'ğŸ', 'ğŸ’¡', 'ğŸ¤—', 'ğŸ‡¨ğŸ‡³', 'âšª', 'ğŸ¤', 'ğŸ§ğŸ»\\u200dâ™‚ï¸', 'ğŸ', 'ğŸ´', 'ğŸ³ï¸', 'ğŸŠ\\u200dâ™€ï¸', 'ğŸš´\\u200dâ™€ï¸', 'ğŸ…', 'ğŸ¥‡', 'ğŸ¥ˆ', 'ğŸ¥‰', 'ğŸ‘ğŸ¾', 'ğŸ‚', 'ğŸ', 'ğŸ”ï¸', 'ğŸ’»', 'ğŸ´\\U000e0067\\U000e0062\\U000e0065\\U000e006e\\U000e0067\\U000e007f', 'ğŸ´\\U000e0067\\U000e0062\\U000e0077\\U000e006c\\U000e0073\\U000e007f', 'ğŸ´\\U000e0067\\U000e0062\\U000e0073\\U000e0063\\U000e0074\\U000e007f', 'ğŸ‡¬ğŸ‡§', 'ğŸ°', 'ğŸ¤‘', 'ğŸ”½', 'ğŸ–¼ï¸', 'ğŸ™Š', 'âºï¸', 'ğŸ¤·ğŸ¿\\u200dâ™‚ï¸', 'ğŸ”’', 'ğŸ¤·ğŸ¾\\u200dâ™‚ï¸', 'ğŸˆ', 'ğŸ†˜', 'ğŸ˜µ', 'ğŸŒ†', 'ğŸš•', 'ğŸ¤²ğŸ½', 'âœï¸', 'ğŸŠğŸ½\\u200dâ™‚ï¸', 'ğŸ”Š', 'ğŸ—¿', 'ğŸš', 'ğŸ’ªğŸ¾', 'ğŸ‚', 'ğŸ”ª', 'ğŸ™ğŸ½', 'ğŸ˜¹', 'ğŸ¤¦ğŸ»\\u200dâ™€ï¸', 'ğŸ…¿', 'ğŸ…¾', 'Â®ï¸', 'ğŸ…¾ï¸', 'ğŸ’¤', 'ğŸ…°', 'ğŸ…¿ï¸', 'ğŸ‡©ğŸ‡ª', 'ğŸ’°', 'ğŸ”', 'ğŸ‡³ğŸ‡±', 'ğŸ‘ŒğŸ»', 'ğŸ‡ªğŸ‡¦', 'ğŸ”¯', 'ğŸ¤ğŸ»', 'ğŸ›', 'ğŸ’²', 'ğŸ‡«ğŸ‡·', 'ğŸ‡ªğŸ‡¸', 'ğŸ’‚\\u200dâ™€ï¸', 'ğŸ¸', 'â™€', 'ğŸ‘¸', 'ğŸ—º', 'â°', 'ğŸ‘ˆğŸ¼', 'ğŸ––ğŸ»', 'ğŸ', 'ğŸ”µ', 'ğŸ¤¦ğŸ½\\u200dâ™‚ï¸', 'ğŸ¤³', 'ğŸ˜¸', 'ğŸ’’', 'ğŸ›’', 'ğŸŒ¿', 'ğŸ‡ºğŸ‡¬', 'âœŒğŸ¾', 'â™¿', 'ğŸ‘­', 'ğŸ—³', 'ğŸ‘¥', 'ğŸ”ƒ', 'ğŸ‘', 'ğŸ‘‹ğŸ¼', 'ğŸ“…', 'ğŸ›', 'ğŸ’·', 'â“', 'ğŸ¤', 'ğŸ¤Ÿ', 'ğŸ‘ğŸ½', 'â›“ï¸', 'ğŸ€', 'â›ª', 'ğŸ‡¦ğŸ‡º', 'â˜¯', 'ğŸ™…', 'ğŸ¦', 'â™¾', 'ğŸ¤ğŸ»', 'ğŸ”·', 'ğŸ•Š', 'ğŸ’', 'ğŸ‹ğŸ½\\u200dâ™‚ï¸', 'ğŸ¤¦ğŸ¿\\u200dâ™€', 'ğŸ™', 'ğŸ‡¨ğŸ‡®', 'ğŸ‡¸ğŸ‡´', 'ğŸ‡ºğŸ‡¿', 'ğŸ¤·ğŸ¾\\u200dâ™€ï¸', 'ğŸ²', 'ğŸ‘­ğŸ¾', 'ğŸ’…ğŸ¼', 'ğŸ ', 'ğŸ›¸', 'ğŸ¤˜', 'ğŸŒš', 'ğŸ”„', 'âœŒğŸ¼', 'ğŸ“', 'ğŸ’…ğŸ¾', 'ğŸŒ', 'ğŸ§', 'ğŸ¤·ğŸ»', 'ğŸ¦†', 'ğŸ¤', 'ğŸ”', 'ğŸ—‘ï¸', 'ğŸ¤–', 'ğŸ“˜', 'ğŸ’', 'ğŸ‡¬ğŸ‡­', 'âš–', 'ğŸŸ', 'ğŸ™‹ğŸ¾\\u200dâ™€ï¸', 'âš½', 'ğŸƒ', 'â˜”', 'ğŸ‘¼']\n"
     ]
    }
   ],
   "source": [
    "emoji_df = pd.read_csv('emoji.csv')\n",
    "emoji_list = emoji_df['emoji'].to_list()\n",
    "print(emoji_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2lgbtqias', '2nite', 'abbasi', 'ade', 'aku', 'atonia', 'awwww', 'bagus', 'benda', 'biden', 'bradbury', 'cee', 'chakra', 'charle', 'cosa', 'covid-19', 'cupcakke', 'elysia', 'etcnon', 'fair1', 'familia', 'fil', 'furrie', 'gc', 'georgiafreedom', 'goldwater', 'gop', 'grat', 'grt', 'gta', 'hak', 'ig', 'inb4', 'kadhi', 'kalo', 'karlsberg', 'koda', 'kulah', 'l3sbians', 'latifi', 'lgbt2', 'lgbtabc123xyz', 'lgbtq', 'lgbtq2', 'lgbtqia2', 'lgbtÃ·', 'looney', 'mau', 'nep', 'peele', 'ppls', 'proship', 'proshpped0', 'rated18', 'rogan', 'rostow', 'rp', 'sama', 'su1c1de', 'tabeta', 'titanbi', 'vag', 'vinny', 'visto', 'wickham', 'ww2', 'yagi', 'zahra', 'æ–°äººvtuber']\n"
     ]
    }
   ],
   "source": [
    "vocab_df = pd.read_csv('vocab.csv')\n",
    "vocab_list = vocab_df['word'].to_list()\n",
    "print(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 660 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(31182, 768)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokens = emoji_list + vocab_list\n",
    "\n",
    "num_added_toks = tokenizer.add_tokens(new_tokens)\n",
    "print('We have added', num_added_toks, 'tokens')\n",
    " # Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e., the length of the tokenizer.\n",
    "bert.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data\n",
    "text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\n",
    "\n",
    "# encode text\n",
    "sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 2023, 2003, 1037, 14324, 2944, 14924, 4818, 102, 0], [101, 2057, 2097, 2986, 1011, 8694, 1037, 14324, 2944, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "# output\n",
    "print(sent_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get length of all the messages in the train set\n",
    "seq_len = [len(i.split()) for i in train_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    padding='longest',\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    padding='longest',\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    padding='longest',\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train set\n",
    "train_seq = torch.tensor(tokens_train['input_ids']).to(device)\n",
    "train_mask = torch.tensor(tokens_train['attention_mask']).to(device)\n",
    "train_y = torch.tensor(train_labels.tolist()).to(device)\n",
    "\n",
    "# for validation set\n",
    "val_seq = torch.tensor(tokens_val['input_ids']).to(device)\n",
    "val_mask = torch.tensor(tokens_val['attention_mask']).to(device)\n",
    "val_y = torch.tensor(val_labels.tolist()).to(device)\n",
    "\n",
    "# for test set\n",
    "test_seq = torch.tensor(tokens_test['input_ids']).to(device)\n",
    "test_mask = torch.tensor(tokens_test['attention_mask']).to(device)\n",
    "test_y = torch.tensor(test_labels.tolist()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 16\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "      \n",
    "      super(BERT_Arch, self).__init__()\n",
    "\n",
    "      self.bert = bert \n",
    "      \n",
    "      # dropout layer\n",
    "      self.dropout = nn.Dropout(0.1)\n",
    "      \n",
    "      # relu activation function\n",
    "      self.relu =  nn.ReLU()\n",
    "\n",
    "      # dense layer 1\n",
    "      self.fc1 = nn.Linear(768,512)\n",
    "      \n",
    "      # dense layer 2 (Output layer)\n",
    "      self.fc2 = nn.Linear(512,3)\n",
    "\n",
    "      #softmax activation function\n",
    "      self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "\n",
    "      #pass the inputs to the model  \n",
    "      _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
    "      \n",
    "      x = self.fc1(cls_hs)\n",
    "\n",
    "      x = self.relu(x)\n",
    "\n",
    "      x = self.dropout(x)\n",
    "\n",
    "      # output layer\n",
    "      x = self.fc2(x)\n",
    "      \n",
    "      # apply softmax activation\n",
    "      x = self.softmax(x)\n",
    "\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# optimizer from hugging face transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.79588669 0.90478983 0.74741602]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#compute the class weights\n",
    "class_wts = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "\n",
    "print(class_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class weights to tensor\n",
    "weights= torch.tensor(class_wts,dtype=torch.float)\n",
    "weights = weights.to(device)\n",
    "\n",
    "# loss function\n",
    "cross_entropy  = nn.NLLLoss(weight=weights) \n",
    "\n",
    "# number of training epochs\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "  \n",
    "  model.train()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save model predictions\n",
    "  total_preds=[]\n",
    "  \n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(train_dataloader):\n",
    "    \n",
    "    # progress update after every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [r.to(device) for r in batch]\n",
    " \n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # clear previously calculated gradients \n",
    "    model.zero_grad()        \n",
    "\n",
    "    # get model predictions for the current batch\n",
    "    preds = model(sent_id, mask)\n",
    "\n",
    "    # compute the loss between actual and predicted values\n",
    "    loss = cross_entropy(preds, labels)\n",
    "\n",
    "    # add on to the total loss\n",
    "    total_loss = total_loss + loss.item()\n",
    "\n",
    "    # backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # model predictions are stored on GPU. So, push it to CPU\n",
    "    preds=preds.detach().cpu().numpy()\n",
    "\n",
    "    # append the model predictions\n",
    "    total_preds.append(preds)\n",
    "\n",
    "  # compute the training loss of the epoch\n",
    "  avg_loss = total_loss / len(train_dataloader)\n",
    "  \n",
    "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  #returns the loss and predictions\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "  \n",
    "  print(\"\\nEvaluating...\")\n",
    "  \n",
    "  # deactivate dropout layers\n",
    "  model.eval()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save the model predictions\n",
    "  total_preds = []\n",
    "\n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(val_dataloader):\n",
    "    \n",
    "    # Progress update every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "            \n",
    "      # Report progress.\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [t.to(device) for t in batch]\n",
    "\n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # deactivate autograd\n",
    "    with torch.no_grad():\n",
    "      \n",
    "      # model predictions\n",
    "      preds = model(sent_id, mask)\n",
    "\n",
    "      # compute the validation loss between actual and predicted values\n",
    "      loss = cross_entropy(preds,labels)\n",
    "\n",
    "      total_loss = total_loss + loss.item()\n",
    "\n",
    "      preds = preds.detach().cpu().numpy()\n",
    "\n",
    "      total_preds.append(preds)\n",
    "\n",
    "  # compute the validation loss of the epoch\n",
    "  avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 10\n",
      "  Batch    50  of    868.\n",
      "  Batch   100  of    868.\n",
      "  Batch   150  of    868.\n",
      "  Batch   200  of    868.\n",
      "  Batch   250  of    868.\n",
      "  Batch   300  of    868.\n",
      "  Batch   350  of    868.\n",
      "  Batch   400  of    868.\n",
      "  Batch   450  of    868.\n",
      "  Batch   500  of    868.\n",
      "  Batch   550  of    868.\n",
      "  Batch   600  of    868.\n",
      "  Batch   650  of    868.\n",
      "  Batch   700  of    868.\n",
      "  Batch   750  of    868.\n",
      "  Batch   800  of    868.\n",
      "  Batch   850  of    868.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    186.\n",
      "  Batch   100  of    186.\n",
      "  Batch   150  of    186.\n",
      "\n",
      "Training Loss: 1.117\n",
      "Validation Loss: 1.098\n",
      "\n",
      " Epoch 2 / 10\n",
      "  Batch    50  of    868.\n",
      "  Batch   100  of    868.\n",
      "  Batch   150  of    868.\n",
      "  Batch   200  of    868.\n",
      "  Batch   250  of    868.\n",
      "  Batch   300  of    868.\n",
      "  Batch   350  of    868.\n",
      "  Batch   400  of    868.\n",
      "  Batch   450  of    868.\n",
      "  Batch   500  of    868.\n",
      "  Batch   550  of    868.\n",
      "  Batch   600  of    868.\n",
      "  Batch   650  of    868.\n",
      "  Batch   700  of    868.\n",
      "  Batch   750  of    868.\n",
      "  Batch   800  of    868.\n",
      "  Batch   850  of    868.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    186.\n",
      "  Batch   100  of    186.\n",
      "  Batch   150  of    186.\n",
      "\n",
      "Training Loss: 1.098\n",
      "Validation Loss: 1.098\n",
      "\n",
      " Epoch 3 / 10\n",
      "  Batch    50  of    868.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Documents\\GitHub\\CZ4045---NLP\\new_bert.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/GitHub/CZ4045---NLP/new_bert.ipynb#X34sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m Epoch \u001b[39m\u001b[39m{:}\u001b[39;00m\u001b[39m / \u001b[39m\u001b[39m{:}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, epochs))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/GitHub/CZ4045---NLP/new_bert.ipynb#X34sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m#train model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/GitHub/CZ4045---NLP/new_bert.ipynb#X34sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m train_loss, _ \u001b[39m=\u001b[39m train()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/GitHub/CZ4045---NLP/new_bert.ipynb#X34sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m#evaluate model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/GitHub/CZ4045---NLP/new_bert.ipynb#X34sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m valid_loss, _ \u001b[39m=\u001b[39m evaluate()\n",
      "\u001b[1;32mc:\\Users\\user\\Documents\\GitHub\\CZ4045---NLP\\new_bert.ipynb Cell 24\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/GitHub/CZ4045---NLP/new_bert.ipynb#X34sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), \u001b[39m1.0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/GitHub/CZ4045---NLP/new_bert.ipynb#X34sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# update parameters\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/GitHub/CZ4045---NLP/new_bert.ipynb#X34sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/GitHub/CZ4045---NLP/new_bert.ipynb#X34sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m# model predictions are stored on GPU. So, push it to CPU\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/GitHub/CZ4045---NLP/new_bert.ipynb#X34sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m preds\u001b[39m=\u001b[39mpreds\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages\\transformers\\optimization.py:362\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    360\u001b[0m exp_avg\u001b[39m.\u001b[39mmul_(beta1)\u001b[39m.\u001b[39madd_(grad, alpha\u001b[39m=\u001b[39m(\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m beta1))\n\u001b[0;32m    361\u001b[0m exp_avg_sq\u001b[39m.\u001b[39mmul_(beta2)\u001b[39m.\u001b[39maddcmul_(grad, grad, value\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m beta2)\n\u001b[1;32m--> 362\u001b[0m denom \u001b[39m=\u001b[39m exp_avg_sq\u001b[39m.\u001b[39;49msqrt()\u001b[39m.\u001b[39;49madd_(group[\u001b[39m\"\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m    364\u001b[0m step_size \u001b[39m=\u001b[39m group[\u001b[39m\"\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    365\u001b[0m \u001b[39mif\u001b[39;00m group[\u001b[39m\"\u001b[39m\u001b[39mcorrect_bias\u001b[39m\u001b[39m\"\u001b[39m]:  \u001b[39m# No bias correction for Bert\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights of best model\n",
    "path = 'saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for test data\n",
    "import torch \n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "with torch.no_grad():\n",
    "  preds = model(test_seq[:1].to(device), test_mask[:1].to(device))\n",
    "  preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Documents\\GitHub\\CZ4045---NLP\\new_bert.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/GitHub/CZ4045---NLP/new_bert.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m classification_report\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/GitHub/CZ4045---NLP/new_bert.ipynb#X46sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# model's performance\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/GitHub/CZ4045---NLP/new_bert.ipynb#X46sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m preds \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49margmax(preds, axis \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/GitHub/CZ4045---NLP/new_bert.ipynb#X46sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(classification_report(test_y, preds[:\u001b[39m1\u001b[39m]))\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1216\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m \u001b[39mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1213\u001b[0m \u001b[39m(2, 1, 4)\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m kwds \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mkeepdims\u001b[39m\u001b[39m'\u001b[39m: keepdims} \u001b[39mif\u001b[39;00m keepdims \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39m_NoValue \u001b[39melse\u001b[39;00m {}\n\u001b[1;32m-> 1216\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39m\u001b[39margmax\u001b[39m\u001b[39m'\u001b[39m, axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "\n",
    "# model's performance\n",
    "preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arts', '##y', '##7']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "pd.crosstab(test_y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "61d7d72412218704c5ba1799d65c7a83b08e24a9ca7847de9a479f6f426633e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
