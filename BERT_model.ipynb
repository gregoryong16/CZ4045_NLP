{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-1b67030b753636ac\n",
      "Reusing dataset csv (C:\\Users\\user\\.cache\\huggingface\\datasets\\csv\\default-1b67030b753636ac\\0.0.0\\652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3495a74cf2294d27b479d4eb095c26d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "base_url = './data/'\n",
    "\n",
    "dataset = load_dataset('csv', data_files={'train': base_url+'bert_train.csv','validation': base_url+'bert_val.csv','test': base_url+'bert_test.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce GTX 1650\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['â„¢', 'ðŸ™„', 'âœ…', 'ðŸ’—', 'ðŸ˜¢', 'ðŸ³ï¸\\u200dðŸŒˆ', 'ðŸ˜Œ', 'ðŸ³', 'ðŸ’€', 'ðŸŒˆ', 'ðŸ‘ðŸ»', 'âœ¨', 'ðŸŒŸ', 'ðŸŒ¹', 'ðŸ˜•', 'â­', 'ðŸ˜…', 'ðŸ™', 'ðŸ’', 'ðŸ§', 'ðŸ˜­', 'ðŸ–¤', 'ðŸ¤§', 'ðŸ¤£', 'ðŸ—ƒï¸', 'ðŸ—“ï¸', 'âž¡ï¸', 'ðŸ”»', 'ðŸ¤¤', 'ðŸŒ', 'ðŸ˜', 'â¤ï¸', 'â¤', 'ðŸ‘', 'ðŸ˜', 'ðŸ‘½', 'ðŸš€', 'ðŸ“š', 'ðŸ±', 'ðŸŒŒ', 'ðŸ˜©', 'ðŸ¤·\\u200dâ™€ï¸', 'ðŸ˜¬', 'ðŸ¦„', 'ðŸ¤¸\\u200dâ™€ï¸', 'â˜€ï¸', 'ðŸ‘ðŸ¼', 'ðŸ”†', 'ðŸ—£', 'ðŸ‘€', 'ðŸ‘ðŸ»', 'ðŸ§‘\\u200dðŸ¤\\u200dðŸ§‘', 'ðŸŽŠ', 'â˜¹ï¸', 'ðŸ¥°', 'ðŸ’–', 'ðŸ¤­', 'ðŸ‘Ž', 'ðŸŽµ', 'ðŸŽ¶', 'ðŸ˜Š', 'ðŸ‘ŒðŸ¼', 'ðŸ¤ŸðŸ¼', 'ðŸ’ªðŸ¼', 'ðŸ”¥', 'ðŸ»', 'ðŸº', 'ðŸ˜‚', 'â™¥ï¸', 'ðŸ¤¡', 'ðŸ’š', 'ðŸ’™', 'ðŸ’œ', 'ðŸ¤”', 'ðŸ¹', 'ðŸ¸', 'ðŸ‘Œ', 'ðŸ ', 'ðŸ™ƒ', 'ðŸš«', 'ðŸ‘‡', 'ðŸ˜†', 'ðŸ˜€', 'ðŸ¤ª', 'ðŸ¤·ðŸ¼\\u200dâ™‚ï¸', 'ðŸ¥º', 'ðŸ“¦', 'ðŸƒ', 'ðŸ’¨', 'ðŸŒ…', 'ðŸ', 'ðŸ‘¬ðŸ»', 'ðŸ¥µ', 'ðŸ§µ', 'ðŸ˜°', 'ðŸ’…', 'ðŸ‘¨\\u200dâ¤ï¸\\u200dðŸ‘¨', 'ðŸ‘¨\\u200dâ¤ï¸\\u200dðŸ’‹\\u200dðŸ‘¨', 'ðŸ˜”', 'ðŸ˜‡', 'ðŸ¤«', 'ðŸ™ðŸ»', 'ðŸ¤·\\u200dâ™‚ï¸', 'ðŸ‡§ðŸ‡¿', 'ðŸ˜ž', 'ðŸ“£', 'ðŸ¤¢', 'ðŸ˜ƒ', 'ðŸ˜¡', 'ðŸ’«', 'ðŸ’Ž', 'ðŸ§›\\u200dâ™€ï¸', 'ðŸ¥€', 'ðŸŽ¹', 'â„¢ï¸', 'ðŸ˜º', 'ðŸ¤', 'ðŸ’›', 'ðŸ§¡', 'ðŸ’•', 'âœ‹', 'ðŸ—½', 'ðŸŽƒ', 'ðŸ‡·ðŸ‡º', 'ðŸ¤ ', 'ðŸ’‹', 'ðŸ¤¯', 'ðŸŽ©', 'ðŸ§', 'ðŸ°', 'âœŒï¸', 'ðŸ‘¨', 'ðŸ‘¨ðŸ¼', 'ðŸ¥´', 'ðŸ’”', 'ðŸ‘', 'Â®', 'ðŸ˜Ž', 'ðŸ•', 'ðŸ’©', 'ðŸ¨', 'ðŸ˜‰', 'ðŸ§', 'ðŸ‘ðŸ¾', 'ðŸ˜³', 'ðŸ¥³', 'ðŸ¤¦\\u200dâ™€ï¸', 'ðŸ‘‡ðŸ½', 'ðŸ”º', 'ðŸ™Œ', 'âŒ', 'â­•', 'ðŸ˜™', 'ðŸ¤¦\\u200dâ™‚ï¸', 'ðŸ¤¦\\u200dâ™‚', 'ðŸ˜‘', 'ðŸ’¥', 'âž¡', 'ðŸ”´', 'ðŸŽ®', 'ðŸš‘', 'â›‘ï¸', 'ðŸ˜', 'ðŸ—£ï¸', 'ðŸ’¬', 'ðŸ˜¿', 'ðŸ˜ˆ', 'ðŸ˜', 'ðŸ’Ÿ', 'â–¶ï¸', 'ðŸŒŽ', 'ðŸŒž', 'ðŸ¤®', 'ðŸ’ªðŸ»', 'ðŸ˜’', 'âœŠðŸ¾', 'â˜', 'ðŸ¦‰', 'ðŸ™‚', 'ðŸ“–', 'ðŸŽ‰', 'ðŸ¤·ðŸ»\\u200dâ™‚ï¸', 'ðŸ…°ï¸', 'ðŸ“Œ', 'ðŸ“·', 'ðŸ‘ðŸ¼', 'â”', 'ðŸ‘¶ðŸ»', 'ðŸ‘§ðŸ»', 'ðŸ™ˆ', 'ðŸ˜˜', 'ðŸ‡', 'ðŸ¿', 'âš«', 'ðŸ‘‹', 'ðŸ˜ª', 'ðŸ’‰', 'â˜ ï¸', 'ðŸ‡ºðŸ‡²', 'ðŸ¤¦', 'ðŸ˜¶', 'ðŸ’“', 'â˜º', 'ðŸ³\\u200dðŸŒˆ', 'âš“', 'ðŸ¥‚', 'Â©ï¸', 'âœŠ', '1ï¸âƒ£', '5ï¸âƒ£', 'ðŸ˜', 'ðŸ¤¦ðŸ»\\u200dâ™‚ï¸', 'ðŸ‡¨ðŸ‡¦', 'ðŸ˜£', 'ðŸš’', 'âœŠðŸ½', 'ðŸ¤¬', 'ðŸ‡ºðŸ‡¦', 'ðŸŽ¥', 'ðŸ¾', 'ðŸš¨', 'â˜ï¸', 'ðŸ¤·ðŸ½\\u200dâ™€ï¸', 'ðŸ¤¨', 'âœï¸', 'ðŸ’…ðŸ»', 'â¬‡', 'ðŸŒ»', 'ðŸ˜·', 'ðŸ¦‹', 'ðŸŒ³', 'ðŸ¦¥', 'ðŸŽ¤', 'ðŸ“', 'ðŸ˜„', 'ðŸ˜“', 'ðŸ’ðŸ»\\u200dâ™‚ï¸', 'ðŸš©', 'ðŸ¤¦ðŸ¼\\u200dâ™‚ï¸', 'ðŸ’', 'ðŸ‘‘', 'âœŒ', 'ðŸŽ§', 'ðŸ¤¦ðŸ¾\\u200dâ™‚ï¸', 'ðŸŒ¸', 'ðŸ–‹', 'ðŸ“¨', 'ðŸ“', 'ðŸ•', 'ðŸ‘®\\u200dâ™‚ï¸', 'ðŸš”', 'ðŸ‘®\\u200dâ™€ï¸', 'ðŸ¤·ðŸ¼\\u200dâ™€ï¸', 'ðŸ–•', 'ðŸ¤¦ðŸ½\\u200dâ™€ï¸', 'ðŸ•“', 'ðŸ‘¹', 'ðŸ¤©', 'ðŸ‘‰', 'ðŸ‘ˆ', 'ðŸ“¼', 'ðŸ›‘', 'â˜Ž', 'âœðŸ»', 'ðŸ˜ ', 'ðŸ€', 'ðŸ¤œðŸ½', 'ðŸ¤›ðŸ½', 'ðŸ”—', 'ðŸ¥', 'ðŸ™‹', 'ðŸ—‘', 'ðŸ‘®ðŸ»\\u200dâ™‚ï¸', 'ðŸ‘·ðŸ¼\\u200dâ™€ï¸', 'ðŸ¥±', 'ðŸ˜»', 'ðŸ‡µðŸ‡¸', 'ðŸ‘¾', 'ðŸš', 'â„ï¸', 'ðŸ‡¸ðŸ‡©', 'ðŸ‡¸ðŸ‡²', 'â˜ºï¸', 'ðŸ¦Š', 'ðŸ‘»', 'ðŸ¤Ž', 'ðŸ˜š', 'â—', 'ðŸ˜¤', 'ðŸ˜œ', 'ðŸ§‘', 'ðŸŽ¼', 'ðŸ‡¦ðŸ‡«', 'ðŸ‘', 'ðŸ‘ï¸', 'ðŸ™…ðŸ»\\u200dâ™€ï¸', 'ðŸ•ºðŸ½', 'ðŸ˜¨', 'ðŸ˜¥', 'ðŸ“º', 'ðŸŽ¬', 'ðŸ“ž', 'ðŸŒï¸\\u200dâ™‚ï¸', 'â›³', 'ðŸ¨', 'ðŸ”', 'ðŸŸ', 'ðŸ’ª', 'ðŸ‘‡ðŸ»', 'ðŸ‡ºðŸ‡¸', 'âœŠðŸ¼', 'ðŸ–•ðŸ»', 'ðŸ˜±', 'ðŸ”«', 'â™£ï¸', 'ðŸ”–', 'â¬œ', 'ðŸ“•', 'ðŸ‘¿', 'ðŸ™ðŸ¼', 'ðŸ˜¦', 'ðŸ¯', 'ðŸ¦µðŸ¿', 'ðŸ’ƒ', 'ðŸ¦…', 'ðŸŽ‚', 'â¬‡ï¸', 'ðŸ’¸', 'ðŸ’¯', 'âœŠðŸ»', 'ðŸ¦ˆ', 'ðŸ€', 'ðŸ‘ðŸ½', 'â˜®ï¸', 'ðŸ˜«', 'ðŸ™‹ðŸ»\\u200dâ™€ï¸', 'ðŸ‘„', 'ðŸ‚', 'ðŸ§›\\u200dâ™€', 'âš”', 'ðŸ˜Ÿ', 'ðŸ‡·ðŸ‡¸', 'ðŸ‡¬ðŸ‡ª', 'â¤µï¸', 'ðŸ˜‹', 'ðŸ‡§ðŸ‡¬', 'ðŸ‡±ðŸ‡»', 'ðŸ‡·ðŸ‡´', 'ðŸ‡¸ðŸ‡°', 'ðŸ‡¨ðŸ‡¿', 'ðŸ‡µðŸ‡±', 'ðŸ‡±ðŸ‡¹', 'ðŸ‡ªðŸ‡ª', 'ðŸ‡­ðŸ‡º', 'ðŸ‡¸ðŸ‡®', 'ðŸ‡§ðŸ‡¦', 'ðŸ‡²ðŸ‡ª', 'ðŸ‡¦ðŸ‡±', 'ðŸ‡²ðŸ‡°', 'ðŸ‡½ðŸ‡°', 'ðŸ‡­ðŸ‡·', 'ðŸ‡¬ðŸ‡·', 'âœ”ï¸', 'âœŒðŸ»', 'ðŸ', 'ðŸŽ¯', 'ðŸ¤·\\u200dâ™‚', 'ðŸ“¸', 'ðŸ¥', 'âœ', 'ðŸ™ŽðŸ¼\\u200dâ™€ï¸', 'ðŸ™ŽðŸ¾\\u200dâ™€', 'ðŸ‘ŒðŸ¿', 'ðŸ™ŒðŸ¿', 'ðŸ‘†', 'ðŸ§\\u200dâ™€ï¸', 'ðŸ¤·ðŸ¼', 'ðŸ’ðŸ¾\\u200dâ™€ï¸', 'ðŸ–', 'â™€ï¸', 'âš°ï¸', 'ðŸ¦´', 'ðŸš¦', 'â›‘', 'ðŸ¤š', 'ðŸ·', 'ðŸšŒ', 'â€¼ï¸', 'â‰ï¸', 'ðŸ˜®', 'ðŸ‰', 'ðŸ¤¦ðŸ¼\\u200dâ™€ï¸', 'ðŸŒ–', 'ðŸ¦', 'ðŸ„', 'ðŸ§ ', 'â™¥', 'ðŸ˜¯', 'ðŸ‘Š', 'ðŸ“ˆ', 'âš•ï¸', 'ðŸ‡ºðŸ‡³', 'ðŸ¤·', 'ðŸ†“', 'ðŸ“±', 'ðŸ›Œ', 'ðŸŒŠ', 'ðŸˆ', 'ðŸ‘—', 'ðŸ™‰', 'ðŸ´\\u200dâ˜ ï¸', 'ðŸ¤¦ðŸ»', 'ðŸ¤·ðŸ»\\u200dâ™€ï¸', 'âš”ï¸', 'ðŸ‘ ', 'ðŸ˜–', 'ðŸ§»', 'ðŸ¶', 'ðŸ˜›', 'ðŸ¤™', 'ðŸ‘‡ðŸ¼', 'ðŸ¤“', 'âœ¡ï¸', 'ðŸ‘ŠðŸ½', 'ðŸ’ªðŸ½', 'ðŸ¿', 'ðŸ™ðŸ¾', 'ðŸ•´', 'ðŸ¤šðŸ»', 'ðŸ¡', 'ðŸ‘©\\u200dðŸ«', 'ðŸ“¢', 'ðŸ¤ž', 'ðŸ‘‰ðŸ¼', 'ðŸ‘ðŸ½', 'âš¡', 'ðŸ†', 'ðŸ‡·ðŸ‡¼', 'ðŸ‡¸ðŸ‡¿', 'ðŸ‡»ðŸ‡³', 'â˜¯ï¸', 'â˜•', 'ðŸ‘‹ðŸ»', 'ðŸ¤·ðŸ½\\u200dâ™‚ï¸', 'ðŸŽž', 'ðŸ’¡', 'ðŸ¤—', 'ðŸ‡¨ðŸ‡³', 'âšª', 'ðŸ¤', 'ðŸ§ðŸ»\\u200dâ™‚ï¸', 'ðŸ', 'ðŸ´', 'ðŸ³ï¸', 'ðŸŠ\\u200dâ™€ï¸', 'ðŸš´\\u200dâ™€ï¸', 'ðŸ…', 'ðŸ¥‡', 'ðŸ¥ˆ', 'ðŸ¥‰', 'ðŸ‘ŽðŸ¾', 'ðŸ‚', 'ðŸ', 'ðŸ”ï¸', 'ðŸ’»', 'ðŸ´\\U000e0067\\U000e0062\\U000e0065\\U000e006e\\U000e0067\\U000e007f', 'ðŸ´\\U000e0067\\U000e0062\\U000e0077\\U000e006c\\U000e0073\\U000e007f', 'ðŸ´\\U000e0067\\U000e0062\\U000e0073\\U000e0063\\U000e0074\\U000e007f', 'ðŸ‡¬ðŸ‡§', 'ðŸ°', 'ðŸ¤‘', 'ðŸ”½', 'ðŸ–¼ï¸', 'ðŸ™Š', 'âºï¸', 'ðŸ¤·ðŸ¿\\u200dâ™‚ï¸', 'ðŸ”’', 'ðŸ¤·ðŸ¾\\u200dâ™‚ï¸', 'ðŸˆ', 'ðŸ†˜', 'ðŸ˜µ', 'ðŸŒ†', 'ðŸš•', 'ðŸ¤²ðŸ½', 'âœï¸', 'ðŸŠðŸ½\\u200dâ™‚ï¸', 'ðŸ”Š', 'ðŸ—¿', 'ðŸš', 'ðŸ’ªðŸ¾', 'ðŸ‚', 'ðŸ”ª', 'ðŸ™ðŸ½', 'ðŸ˜¹', 'ðŸ¤¦ðŸ»\\u200dâ™€ï¸', 'ðŸ…¿', 'ðŸ…¾', 'Â®ï¸', 'ðŸ…¾ï¸', 'ðŸ’¤', 'ðŸ…°', 'ðŸ…¿ï¸', 'ðŸ‡©ðŸ‡ª', 'ðŸ’°', 'ðŸ”', 'ðŸ‡³ðŸ‡±', 'ðŸ‘ŒðŸ»', 'ðŸ‡ªðŸ‡¦', 'ðŸ”¯', 'ðŸ¤žðŸ»', 'ðŸ›', 'ðŸ’²', 'ðŸ‡«ðŸ‡·', 'ðŸ‡ªðŸ‡¸', 'ðŸ’‚\\u200dâ™€ï¸', 'ðŸ¸', 'â™€', 'ðŸ‘¸', 'ðŸ—º', 'â°', 'ðŸ‘ˆðŸ¼', 'ðŸ––ðŸ»', 'ðŸŽ', 'ðŸ”µ', 'ðŸ¤¦ðŸ½\\u200dâ™‚ï¸', 'ðŸ¤³', 'ðŸ˜¸', 'ðŸ’’', 'ðŸ›’', 'ðŸŒ¿', 'ðŸ‡ºðŸ‡¬', 'âœŒðŸ¾', 'â™¿', 'ðŸ‘­', 'ðŸ—³', 'ðŸ‘¥', 'ðŸ”ƒ', 'ðŸ‘', 'ðŸ‘‹ðŸ¼', 'ðŸ“…', 'ðŸ›', 'ðŸ’·', 'â“', 'ðŸ¤', 'ðŸ¤Ÿ', 'ðŸ‘ŽðŸ½', 'â›“ï¸', 'ðŸ€', 'â›ª', 'ðŸ‡¦ðŸ‡º', 'â˜¯', 'ðŸ™…', 'ðŸ¦', 'â™¾', 'ðŸ¤ðŸ»', 'ðŸ”·', 'ðŸ•Š', 'ðŸ’', 'ðŸ‹ðŸ½\\u200dâ™‚ï¸', 'ðŸ¤¦ðŸ¿\\u200dâ™€', 'ðŸ™', 'ðŸ‡¨ðŸ‡®', 'ðŸ‡¸ðŸ‡´', 'ðŸ‡ºðŸ‡¿', 'ðŸ¤·ðŸ¾\\u200dâ™€ï¸', 'ðŸŽ²', 'ðŸ‘­ðŸ¾', 'ðŸ’…ðŸ¼', 'ðŸ ', 'ðŸ›¸', 'ðŸ¤˜', 'ðŸŒš', 'ðŸ”„', 'âœŒðŸ¼', 'ðŸ“', 'ðŸ’…ðŸ¾', 'ðŸŒ', 'ðŸ§', 'ðŸ¤·ðŸ»', 'ðŸ¦†', 'ðŸ¤', 'ðŸ”', 'ðŸ—‘ï¸', 'ðŸ¤–', 'ðŸ“˜', 'ðŸ’ž', 'ðŸ‡¬ðŸ‡­', 'âš–', 'ðŸŽŸ', 'ðŸ™‹ðŸ¾\\u200dâ™€ï¸', 'âš½', 'ðŸƒ', 'â˜”', 'ðŸ‘¼']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "emoji_df = pd.read_csv('emoji.csv')\n",
    "emoji_list = emoji_df['emoji'].to_list()\n",
    "print(emoji_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2lgbtqias', '2nite', 'abbasi', 'ade', 'aku', 'atonia', 'awwww', 'bagus', 'benda', 'biden', 'bradbury', 'cee', 'chakra', 'charle', 'cosa', 'covid-19', 'cupcakke', 'elysia', 'etcnon', 'fair1', 'familia', 'fil', 'furrie', 'gc', 'georgiafreedom', 'goldwater', 'gop', 'grat', 'grt', 'gta', 'hak', 'ig', 'inb4', 'kadhi', 'kalo', 'karlsberg', 'koda', 'kulah', 'l3sbians', 'latifi', 'lgbt2', 'lgbtabc123xyz', 'lgbtq', 'lgbtq2', 'lgbtqia2', 'lgbtÃ·', 'looney', 'mau', 'nep', 'peele', 'ppls', 'proship', 'proshpped0', 'rated18', 'rogan', 'rostow', 'rp', 'sama', 'su1c1de', 'tabeta', 'titanbi', 'vag', 'vinny', 'visto', 'wickham', 'ww2', 'yagi', 'zahra', 'æ–°äººvtuber']\n"
     ]
    }
   ],
   "source": [
    "vocab_df = pd.read_csv('vocab.csv')\n",
    "vocab_list = vocab_df['word'].to_list()\n",
    "print(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 660 tokens\n"
     ]
    }
   ],
   "source": [
    "new_tokens = emoji_list + vocab_list\n",
    "\n",
    "num_added_toks = tokenizer.add_tokens(new_tokens)\n",
    "print('We have added', num_added_toks, 'tokens')\n",
    " # Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e., the length of the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\user\\.cache\\huggingface\\datasets\\csv\\default-1b67030b753636ac\\0.0.0\\652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a\\cache-461ca9cf3c71fb17.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9330e9fe4ad340c299d44921dc7367da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\user\\.cache\\huggingface\\datasets\\csv\\default-1b67030b753636ac\\0.0.0\\652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a\\cache-02872931dfb08b19.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 11901\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 3967\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 3967\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "dataset_encoded = dataset.map(tokenize_function, batched=True, batch_size=None)\n",
    "dataset_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['finally', 'my', 'first', 'politician', 'blocked', 'me', 'i', 'am', 'feeling', 'of', 'myself', 'r', 'ig', 'h', '##t', 'now', 'ðŸ˜†']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.tokenize('finally my first politician blocked me i am feeling of myself right now ðŸ˜†'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'finally my first politician blocked me i am feeling of myself right now ðŸ˜†', 'label': 2, 'input_ids': [101, 2633, 2026, 2034, 3761, 8534, 2033, 1045, 2572, 3110, 1997, 2870, 1054, 31144, 1044, 2102, 2085, 30602, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(dataset_encoded['train'][17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(31182, 768)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "num_labels = 3\n",
    "model = (AutoModelForSequenceClassification\n",
    "         .from_pretrained(checkpoint, num_labels=num_labels)\n",
    "         .to(device))\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "batch_size = 16\n",
    "logging_steps = len(dataset_encoded[\"train\"]) // batch_size\n",
    "model_name = f\"{checkpoint}-finetuned\"\n",
    "training_args = TrainingArguments(output_dir=model_name,\n",
    "                                  num_train_epochs=5,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  disable_tqdm=False,\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  log_level=\"error\",\n",
    "                                  optim='adamw_torch'\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "metric = load_metric('accuracy')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa68afd1e174c6a99ad2767f3ffba6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6797, 'learning_rate': 1.6005376344086022e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52b098c96b8c4e95b37304f803357b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5421019792556763, 'eval_accuracy': 0.7859843710612554, 'eval_runtime': 41.5766, 'eval_samples_per_second': 95.414, 'eval_steps_per_second': 5.965, 'epoch': 1.0}\n",
      "{'loss': 0.4205, 'learning_rate': 1.2010752688172046e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f265a84cd64a89a268064b5d767055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.517335057258606, 'eval_accuracy': 0.8099319384925636, 'eval_runtime': 41.4091, 'eval_samples_per_second': 95.8, 'eval_steps_per_second': 5.989, 'epoch': 2.0}\n",
      "{'loss': 0.2638, 'learning_rate': 8.016129032258066e-06, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47200d416794d70b19102d0498265e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6146219968795776, 'eval_accuracy': 0.8109402571212503, 'eval_runtime': 41.396, 'eval_samples_per_second': 95.83, 'eval_steps_per_second': 5.991, 'epoch': 3.0}\n",
      "{'loss': 0.1753, 'learning_rate': 4.021505376344086e-06, 'epoch': 3.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d296ad259cf94b8d8333a89d6588537a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8216711282730103, 'eval_accuracy': 0.8008570708343836, 'eval_runtime': 41.3828, 'eval_samples_per_second': 95.861, 'eval_steps_per_second': 5.993, 'epoch': 4.0}\n",
      "{'loss': 0.1113, 'learning_rate': 2.688172043010753e-08, 'epoch': 4.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0bb91cedc194ccb97f23bb855d8b808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9536471366882324, 'eval_accuracy': 0.8033778674061003, 'eval_runtime': 41.4516, 'eval_samples_per_second': 95.702, 'eval_steps_per_second': 5.983, 'epoch': 5.0}\n",
      "{'train_runtime': 2215.8245, 'train_samples_per_second': 26.855, 'train_steps_per_second': 1.679, 'train_loss': 0.3296963148820464, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3720, training_loss=0.3296963148820464, metrics={'train_runtime': 2215.8245, 'train_samples_per_second': 26.855, 'train_steps_per_second': 1.679, 'train_loss': 0.3296963148820464, 'epoch': 5.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "trainer = Trainer(model=model,\n",
    "                  compute_metrics=compute_metrics,\n",
    "                  args=training_args, \n",
    "                  train_dataset=dataset_encoded[\"train\"],\n",
    "                  eval_dataset=dataset_encoded[\"validation\"],\n",
    "                  tokenizer=tokenizer)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb6fe2028bd84526aefa5ddb41cf25ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/744 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.06547744572162628,\n",
       " 'eval_accuracy': 0.9843710612553567,\n",
       " 'eval_runtime': 121.6135,\n",
       " 'eval_samples_per_second': 97.859,\n",
       " 'eval_steps_per_second': 6.118,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(dataset_encoded[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011f4dac35224d53844635d1d3bbcc2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0853798389434814,\n",
       " 'eval_accuracy': 0.7842198134610537,\n",
       " 'eval_runtime': 43.2866,\n",
       " 'eval_samples_per_second': 91.645,\n",
       " 'eval_steps_per_second': 5.729,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(dataset_encoded[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b49ebe8e4241189f55349e5b02f6c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output=trainer.predict(dataset_encoded[\"test\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 556,   83,   92],\n",
       "       [  69, 1171,  246],\n",
       "       [  87,  279, 1384]], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm=confusion_matrix(dataset_encoded[\"test\"][\"label\"],predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert-base-uncased-finetuned'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model()\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "model_name = f\"{checkpoint}-finetuned\"\n",
    "classifier = pipeline('text-classification', model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"monkey pox is a hoax all the community hah ðŸ¤¡ ðŸ³ï¸â€ðŸŒˆ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_dict = {\n",
    "    'LABEL_0' : 'NEUTRAL',\n",
    "    'LABEL_1' : 'NEGATIVE',\n",
    "    'LABEL_2' : 'POSITIVE'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence: monkey pox is a hoax all the community hah ðŸ¤¡ ðŸ³ï¸â€ðŸŒˆ\n",
      "\n",
      "This sentence is classified with a NEGATIVE sentiment\n"
     ]
    }
   ],
   "source": [
    "c = classifier(sentence)\n",
    "print(f'\\nSentence: {sentence}')\n",
    "print(f\"\\nThis sentence is classified with a {classifier_dict[c[0]['label']]} sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "61d7d72412218704c5ba1799d65c7a83b08e24a9ca7847de9a479f6f426633e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
